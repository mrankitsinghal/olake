# S3 Driver Testing Setup - Complete Summary

## ğŸ¯ Overview

Comprehensive testing environment for S3 driver with support for **Parquet**, **CSV**, and **JSON** formats, including **Gzip compression** support and **VS Code debugging** capabilities.

## ğŸ“ Files Created

### Configuration Files

| File | Purpose | Format |
|------|---------|--------|
| `source-parquet.json` | Parquet source config | Parquet with Snappy |
| `source-csv.json` | CSV source config | CSV with Gzip support |
| `source-json.json` | JSON source config | JSONL with Gzip support |
| `destination.json` | Iceberg destination | JDBC catalog + S3 |
| `streams.template.json` | Sample streams config | Template for sync modes |

### Infrastructure

| File | Purpose |
|------|---------|
| `docker-compose.yml` | MinIO + PostgreSQL services |
| `.vscode/launch.json` | VS Code debug configurations |

### Test Data Generation

| File | Purpose |
|------|---------|
| `generate_test_data.py` | **Enhanced** - Generates Parquet, CSV, JSON (plain + gzipped) |
| `upload_to_minio.sh` | **Updated** - Uploads all formats to MinIO |

### Scripts

| File | Purpose |
|------|---------|
| `quickstart.sh` | **Updated** - One-command setup for all formats |
| `setup-test-data.sh` | Helper for test data setup |

### Documentation

| File | Purpose |
|------|---------|
| `README.md` | General testing guide |
| `TESTING_GUIDE.md` | **New** - Detailed CSV/JSON/gzip testing guide |
| `SETUP_SUMMARY.md` | **This file** - Quick reference |

## ğŸ—‚ï¸ Generated Test Data Structure

```
test_data/
â”œâ”€â”€ parquet/                    # Parquet files (Snappy compression)
â”‚   â”œâ”€â”€ users/
â”‚   â”‚   â”œâ”€â”€ 2024-01-01/user_data.parquet      (100 records)
â”‚   â”‚   â””â”€â”€ 2024-01-02/user_data.parquet      (120 records)
â”‚   â”œâ”€â”€ orders/
â”‚   â”‚   â”œâ”€â”€ 2024-01-01/order_data.parquet     (150 records)
â”‚   â”‚   â””â”€â”€ 2024-01-02/order_data.parquet     (180 records)
â”‚   â””â”€â”€ products/
â”‚       â””â”€â”€ 2024-01-01/product_data.parquet   (50 records)
â”‚
â”œâ”€â”€ csv/                        # CSV files (plain + gzip)
â”‚   â”œâ”€â”€ users/
â”‚   â”‚   â”œâ”€â”€ 2024-01-01/user_data.csv          (80 records, plain)
â”‚   â”‚   â””â”€â”€ 2024-01-02/user_data.csv.gz       (90 records, gzipped) âœ…
â”‚   â”œâ”€â”€ orders/
â”‚   â”‚   â”œâ”€â”€ 2024-01-01/order_data.csv         (120 records, plain)
â”‚   â”‚   â””â”€â”€ 2024-01-02/order_data.csv.gz      (140 records, gzipped) âœ…
â”‚   â””â”€â”€ products/
â”‚       â””â”€â”€ 2024-01-01/product_data.csv.gz    (40 records, gzipped) âœ…
â”‚
â”œâ”€â”€ json/                       # JSON files (JSONL + array, plain + gzip)
â”‚   â”œâ”€â”€ users/
â”‚   â”‚   â”œâ”€â”€ 2024-01-01/user_data.jsonl        (60 records, JSONL plain)
â”‚   â”‚   â””â”€â”€ 2024-01-02/user_data.jsonl.gz     (75 records, JSONL gzipped) âœ…
â”‚   â”œâ”€â”€ orders/
â”‚   â”‚   â”œâ”€â”€ 2024-01-01/order_data.json        (100 records, JSON array)
â”‚   â”‚   â””â”€â”€ 2024-01-02/order_data.json.gz     (110 records, array gzipped) âœ…
â”‚   â””â”€â”€ products/
â”‚       â””â”€â”€ 2024-01-01/product_data.jsonl.gz  (30 records, JSONL gzipped) âœ…
â”‚
â””â”€â”€ mixed/                      # Mixed formats (for auto-detection testing)
    â””â”€â”€ transactions/
        â”œâ”€â”€ 2024-01-03/data.parquet           (50 records)
        â”œâ”€â”€ 2024-01-03/data.csv.gz            (60 records, gzipped) âœ…
        â””â”€â”€ 2024-01-03/data.jsonl             (20 records)
```

**Summary:**
- **18 total files** across 4 format categories
- **10 distinct streams** (3 per format + 1 mixed)
- **6 gzipped files** marked with âœ…
- **1,395 total records** across all formats

## ğŸš€ Quick Start Commands

### Option 1: Automated Setup (Recommended)

```bash
cd /Users/ankit.singhal/Developer/personal/olake/drivers/s3/examples
./quickstart.sh
```

This runs:
1. âœ… Start MinIO + PostgreSQL
2. âœ… Generate test files (Parquet, CSV, JSON with gzip)
3. âœ… Upload to MinIO
4. âœ… Build S3 driver
5. âœ… Discover streams for all formats

### Option 2: Manual Steps

```bash
# 1. Start services
cd drivers/s3/examples
docker compose up -d

# 2. Generate test data (includes CSV + JSON with gzip)
python3 generate_test_data.py

# 3. Upload to MinIO
./upload_to_minio.sh

# 4. Test each format
cd ../../..

# Parquet
./build.sh driver-s3 discover --config $(pwd)/drivers/s3/examples/source-parquet.json

# CSV (with gzip)
./build.sh driver-s3 discover --config $(pwd)/drivers/s3/examples/source-csv.json

# JSON (with gzip)
./build.sh driver-s3 discover --config $(pwd)/drivers/s3/examples/source-json.json
```

## ğŸ› VS Code Debugging

### Launch Configurations Added

The `.vscode/launch.json` now includes **11 S3-specific debug configurations**:

#### Discovery Debugging
1. **S3: Check Connection** - Test S3 connectivity
2. **S3: Discover - Parquet** - Debug Parquet file discovery
3. **S3: Discover - CSV** - Debug CSV (+ gzip) discovery
4. **S3: Discover - JSON** - Debug JSON/JSONL (+ gzip) discovery

#### Sync Debugging (Full Load)
5. **S3: Sync - Parquet (No State)** - Full backfill of Parquet files
6. **S3: Sync - CSV (No State)** - Full backfill of CSV files
7. **S3: Sync - JSON (No State)** - Full backfill of JSON files

#### Sync Debugging (Incremental)
8. **S3: Sync - Parquet (With State)** - Incremental Parquet sync
9. **S3: Sync - CSV (With State)** - Incremental CSV sync (tests gzip)
10. **S3: Sync - JSON (With State)** - Incremental JSON sync (tests gzip)

#### Utilities
11. **S3: Spec** - View driver specification

### How to Use

1. Open VS Code in the OLake workspace
2. Go to **Run and Debug** (â‡§âŒ˜D or Ctrl+Shift+D)
3. Select configuration from dropdown
4. Set breakpoints in S3 driver code
5. Press **F5** to start debugging

**Recommended Breakpoints:**
- `drivers/s3/internal/s3.go:150` - File discovery
- `drivers/s3/internal/s3.go:250` - Schema inference
- `drivers/s3/internal/incremental.go:80` - Incremental filtering
- `drivers/s3/internal/parsers.go:50` - CSV/JSON parsing

## ğŸ§ª Test Coverage

### Formats
| Format | Plain | Gzipped | Tested |
|--------|-------|---------|--------|
| Parquet | âœ… (Snappy) | N/A | âœ… |
| CSV | âœ… | âœ… | âœ… |
| JSON | âœ… | âœ… | âœ… |
| JSONL | âœ… | âœ… | âœ… |

### Compression
| Type | Extension | Auto-detect | Tested |
|------|-----------|-------------|--------|
| Snappy | .parquet | âœ… | âœ… |
| Gzip | .gz | âœ… | âœ… |
| None | various | âœ… | âœ… |

### Features
| Feature | Parquet | CSV | JSON | Status |
|---------|---------|-----|------|--------|
| Discovery | âœ… | âœ… | âœ… | âœ… |
| Schema Inference | âœ… | âœ… | âœ… | âœ… |
| Schema Caching | âœ… | âœ… | âœ… | âœ… |
| Full Load | âœ… | âœ… | âœ… | âœ… |
| Incremental Sync | âœ… | âœ… | âœ… | âœ… |
| Gzip Support | N/A | âœ… | âœ… | âœ… |

## ğŸ“Š Test Scenarios

### Scenario 1: CSV with Gzip Compression
```bash
# Configuration highlights from source-csv.json:
{
  "file_format": "csv",
  "compression": "gzip",  # Auto-detects .gz files
  "has_header": true,
  "delimiter": ","
}

# Run test
./build.sh driver-s3 sync \
  --config $(pwd)/drivers/s3/examples/source-csv.json \
  --catalog $(pwd)/drivers/s3/examples/streams-csv.json \
  --destination $(pwd)/drivers/s3/examples/destination.json
```

**Expected Result:**
- Reads `user_data.csv` directly (80 records)
- Decompresses `user_data.csv.gz` automatically (90 records)
- Total: 170 records for users stream

### Scenario 2: JSON Line-Delimited with Gzip
```bash
# Configuration from source-json.json:
{
  "file_format": "json",
  "compression": "gzip",
  "json_line_delimited": true  # JSONL format
}

# Run test
./build.sh driver-s3 sync \
  --config $(pwd)/drivers/s3/examples/source-json.json \
  --catalog $(pwd)/drivers/s3/examples/streams-json.json \
  --destination $(pwd)/drivers/s3/examples/destination.json
```

**Expected Result:**
- Reads `user_data.jsonl` (60 records)
- Decompresses `user_data.jsonl.gz` (75 records)
- Handles both JSONL and JSON array formats
- Total: 135 records for users stream

### Scenario 3: Incremental with Gzipped Files
```bash
# First sync
./build.sh driver-s3 sync \
  --config $(pwd)/drivers/s3/examples/source-csv.json \
  --catalog $(pwd)/drivers/s3/examples/streams-csv.json \
  --destination $(pwd)/drivers/s3/examples/destination.json

# Add new gzipped file
python3 -c "
from generate_test_data import save_csv, generate_users_data
save_csv(generate_users_data('2024-01-03', 50), 
         'test_data/csv/users/2024-01-03/user_data.csv.gz', 
         compressed=True)
"
./upload_to_minio.sh

# Incremental sync (only processes new file)
./build.sh driver-s3 sync \
  --config $(pwd)/drivers/s3/examples/source-csv.json \
  --catalog $(pwd)/drivers/s3/examples/streams-csv.json \
  --destination $(pwd)/drivers/s3/examples/destination.json \
  --state $(pwd)/drivers/s3/examples/state-csv.json
```

**Expected Result:**
- Only processes `2024-01-03/user_data.csv.gz` (50 records)
- State updated with new LastModified timestamp
- Logs: "Syncing 1 modified files for stream users"

## ğŸ” Verification Commands

### Check MinIO Files
```bash
# List all uploaded files
docker exec olake-s3-setup mc ls myminio/source-data/ --recursive

# Check specific gzipped file
docker exec olake-s3-setup mc stat myminio/source-data/csv/users/2024-01-02/user_data.csv.gz

# Download and inspect
docker exec olake-s3-setup mc cat myminio/source-data/csv/users/2024-01-02/user_data.csv.gz | zcat | head
```

### Verify Gzip Compression
```bash
# Check local gzipped files
file test_data/csv/users/2024-01-02/user_data.csv.gz
# Output: gzip compressed data

# Decompress and inspect
zcat test_data/csv/users/2024-01-02/user_data.csv.gz | head -n 3
zcat test_data/json/users/2024-01-02/user_data.jsonl.gz | head -n 2
```

### Query Synced Data
```bash
# Connect to Iceberg catalog
docker exec -it olake-iceberg-catalog psql -U iceberg -d iceberg

# List tables
\dt olake_iceberg.*

# Query CSV data
SELECT COUNT(*) FROM olake_iceberg.users;
SELECT * FROM olake_iceberg.users LIMIT 5;
```

## ğŸ“š Documentation References

| Document | Description |
|----------|-------------|
| **TESTING_GUIDE.md** | Detailed CSV/JSON/gzip testing procedures |
| **README.md** | General S3 driver setup and usage |
| **SETUP_SUMMARY.md** | This file - quick reference |
| [OLake Dev Env Docs](https://olake.io/docs/community/setting-up-a-dev-env/) | Official setup guide |

## âœ… Pre-flight Checklist

Before starting tests:
- [ ] Docker installed and running
- [ ] Python 3.7+ with pandas, pyarrow installed
- [ ] Go 1.25+ installed
- [ ] VS Code with Go extension (for debugging)
- [ ] Ports 9000, 9001, 5432 available

## ğŸ¯ Success Criteria

After running `./quickstart.sh`, you should have:

âœ… **Services Running:**
- MinIO at http://localhost:9001
- PostgreSQL at localhost:5432

âœ… **Test Data Created:**
- 18 files (5 Parquet, 5 CSV, 5 JSON, 3 mixed)
- 6 gzipped files (.csv.gz, .json.gz, .jsonl.gz)
- 1,395 total records

âœ… **Uploaded to MinIO:**
- 4 top-level folders: parquet/, csv/, json/, mixed/
- Visible in MinIO Console

âœ… **Catalogs Generated:**
- catalog_parquet.json (3 streams)
- catalog_csv.json (3 streams)
- catalog_json.json (3 streams)

âœ… **VS Code Ready:**
- 11 debug configurations available
- Can set breakpoints and debug

## ğŸš¨ Common Issues

### Issue: "pandas/pyarrow not found"
```bash
pip install pandas pyarrow
```

### Issue: "Port 9000 already in use"
```bash
# Find and kill process
lsof -ti:9000 | xargs kill -9

# Or use different port in docker-compose.yml
```

### Issue: Gzipped files showing as empty
```bash
# Regenerate test data
rm -rf test_data/
python3 generate_test_data.py

# Verify gzip files locally
zcat test_data/csv/users/2024-01-02/user_data.csv.gz | wc -l
```

## ğŸ‰ What's New

### Enhancements from Initial Setup

1. **Multi-Format Support**
   - Added CSV and JSON alongside Parquet
   - Gzip compression for CSV and JSON files

2. **Enhanced Test Data**
   - 18 files vs. original 5
   - Multiple compression variants
   - Mixed format folder for auto-detection

3. **VS Code Integration**
   - 11 debug configurations vs. original 3
   - Format-specific debugging
   - Incremental sync debugging

4. **Comprehensive Documentation**
   - TESTING_GUIDE.md with detailed scenarios
   - SETUP_SUMMARY.md for quick reference
   - Updated README.md

5. **Better Scripts**
   - Enhanced generate_test_data.py (CSV, JSON, gzip)
   - Updated upload_to_minio.sh for all formats
   - Improved quickstart.sh with multi-format discovery

## ğŸ“ Support

For issues or questions:
- GitHub: https://github.com/datazip-inc/olake/issues
- Slack: [Join OLake Community](https://olake.io)
- Docs: https://olake.io/docs/

---

**Happy Testing! ğŸš€**

You now have a complete S3 driver testing environment with Parquet, CSV, and JSON support, including gzip compression and VS Code debugging capabilities.

