# S3 Driver Testing Guide

Complete testing documentation for the S3 driver with **Go + Shell** (no Python dependencies).

## ğŸš€ Quick Start

**Test everything in 2 minutes with a single command!**

```bash
cd /Users/ankit.singhal/Developer/personal/olake/drivers/s3/examples

# One command to rule them all!
./run_tests.sh
```

That's it! This will:
1. âœ… Start Docker containers (MinIO + PostgreSQL)
2. âœ… Generate test data (Go - no Python!)
3. âœ… Upload to MinIO
4. âœ… Run S3 driver sync (Parquet, CSV, JSON)
5. âœ… Verify data in Iceberg

### Prerequisites

- Docker installed and running
- Go 1.19+ installed

### Test Results

After running, you'll see:

```
=== Record Counts ===
parquet_users:    10,000 records
parquet_orders:   50,000 records
parquet_products:  5,000 records
csv_users:        10,000 records
csv_orders:       50,000 records
csv_products:      5,000 records
json_users:       10,000 records
json_orders:      50,000 records
json_products:     5,000 records

âœ… All Tests Passed!
```

## ğŸ“Š Testing Options

| Test Type | Command | Duration | What It Tests |
|-----------|---------|----------|---------------|
| **Unit Tests** | `go test ./drivers/s3/internal/... -v` | ~2s | Core logic, 154+ tests |
| **Quick Integration** | `./run_tests.sh` | ~2min | Small files, all formats |
| **Medium Integration** | `./run_tests.sh --size medium` | ~10min | ~2.6M records |
| **Large Integration** | `./run_tests.sh --size large` | ~45min | ~15.5M records, 10GB |
| **Chunk Testing** | `./test_chunking.sh` | ~5min | 2GB chunk boundaries |

---

## ğŸ“¦ 1. Unit Tests (Fast)

Test core logic without Docker:

```bash
cd /Users/ankit.singhal/Developer/personal/olake

# All S3 driver tests
go test ./drivers/s3/internal/... -v

# Specific test
go test ./drivers/s3/internal/... -v -run TestGroupFilesIntoChunks
go test ./drivers/s3/internal/... -v -run TestIncrementalSyncFiltering

# With coverage
go test ./drivers/s3/internal/... -cover
```

**Coverage:** 154+ test cases covering:
- Chunking logic
- Cursor-based filtering  
- Configuration validation
- Parser configs
- Edge cases
- Concurrent access

---

## ğŸš€ 2. Integration Tests

End-to-end testing with Docker for all file formats and sizes.

### Small Files (~2 minutes)

```bash
cd drivers/s3/examples
./run_tests.sh
```

**Generates:**
- 10K users, 50K orders, 5K products
- ~65K total records
- ~50MB data
- Tests all formats: Parquet, CSV, JSON

**Verifies:**
- Data in MinIO
- Sync to Iceberg
- All compressions work
- Cursor field present

### Medium Files (~10 minutes)

```bash
./run_tests.sh --size medium
```

**Generates:**
- 1M users, 1.5M orders, 100K products
- ~2.6M total records
- ~2GB data

**Stress tests:**
- Larger datasets
- Memory efficiency
- Chunk grouping

### Large Files (~45 minutes)

```bash
./run_tests.sh --size large
```

**Generates:**
- 5M users, 10M orders, 500K products
- ~15.5M total records
- ~10GB data

**Validates:**
- Large-scale performance
- >2GB file handling
- Streaming mode
- Memory stability

### Test Data Sizes

| Size | Users | Orders | Products | Total Records | Disk Size |
|------|-------|--------|----------|---------------|-----------|
| **small** | 10K | 50K | 5K | ~65K | ~50MB |
| **medium** | 1M | 1.5M | 100K | ~2.6M | ~2GB |
| **large** | 5M | 10M | 500K | ~15.5M | ~10GB |

### What Gets Tested

#### File Formats
- âœ… **Parquet** (Snappy compression)
- âœ… **CSV** (plain + gzip)
- âœ… **JSON** (JSONL format, plain + gzip)

#### Features
- âœ… Multi-format support
- âœ… Compression handling (gzip, snappy)
- âœ… Chunking logic (2GB chunks)
- âœ… Schema inference
- âœ… Incremental sync with `_olake_last_modified`
- âœ… Data integrity in Iceberg

---

## ğŸ§© 3. Chunk Boundary Testing

Test 2GB chunking logic with files of various sizes to verify correct grouping behavior.

### ğŸ¯ What This Tests

The S3 driver groups files into 2GB chunks for parallel processing. This test verifies:

- âœ… **Small files** (<100MB) group together into single 2GB chunks
- âœ… **Medium files** (500MB-1.5GB) group intelligently without exceeding 2GB
- âœ… **Large files** (>2GB) are processed as individual chunks
- âœ… **Edge cases** near the 2GB boundary

### Lite Mode (Recommended for Local Testing) ğŸ’¡

```bash
cd /Users/ankit.singhal/Developer/personal/olake/drivers/s3/examples
./test_chunking.sh
```

**Fast & Lightweight:** Generates 8 files (1-35MB, ~120MB total) in seconds!

### Full Mode (Production Testing) âš ï¸

```bash
./test_chunking.sh --full
```

**Resource Intensive:** Generates 8 files (10MB-3GB, ~7.3GB total). Takes several minutes.

### What The Test Does:
1. Generate test files (lite or full mode)
2. Upload to MinIO
3. Run S3 driver sync
4. Verify chunking behavior in logs
5. Confirm data in Iceberg

### Test Files Generated

#### Lite Mode (Default)

| File Name | Size | Purpose |
|-----------|------|---------|
| `small_1mb.parquet` | ~1MB | Fast grouping test |
| `small_5mb.parquet` | ~5MB | Fast grouping test |
| `small_10mb.parquet` | ~10MB | Fast grouping test |
| `medium_15mb.parquet` | ~15MB | Edge case grouping |
| `medium_20mb.parquet` | ~20MB | Edge case grouping |
| `medium_25mb.parquet` | ~25MB | Edge case grouping |
| `large_30mb.parquet` | ~30MB | Larger file test |
| `large_35mb.parquet` | ~35MB | Larger file test |

**Total:** ~120MB | **Generation Time:** <10 seconds

#### Full Mode (--full flag)

| File Name | Size | Purpose |
|-----------|------|---------|
| `small_10mb.parquet` | 10MB | Should group with others |
| `small_50mb.parquet` | 50MB | Should group with others |
| `small_100mb.parquet` | 100MB | Should group with others |
| `medium_500mb.parquet` | 500MB | Edge case grouping |
| `medium_1gb.parquet` | 1GB | Edge case grouping |
| `medium_1500mb.parquet` | 1.5GB | Edge case grouping |
| `large_2500mb.parquet` | 2.5GB | **Individual chunk** (>2GB) |
| `large_3gb.parquet` | 3GB | **Individual chunk** (>2GB) |

**Total:** ~7.3GB | **Generation Time:** Several minutes

### Expected Chunking Behavior

```
Stream: chunk_test

Small Files (total ~160MB):
  â”œâ”€ small_10mb.parquet (10MB)
  â”œâ”€ small_50mb.parquet (50MB)
  â””â”€ small_100mb.parquet (100MB)
  â†’ **Grouped into 1 chunk** (total < 2GB)

Medium Files (total ~3GB):
  â”œâ”€ medium_500mb.parquet (500MB)
  â”œâ”€ medium_1gb.parquet (1GB)
  â””â”€ medium_1500mb.parquet (1.5GB)
  â†’ **Split into 2 chunks**
     - Chunk 1: 500MB + 1GB = 1.5GB
     - Chunk 2: 1.5GB

Large Files (individual):
  â”œâ”€ large_2500mb.parquet (2.5GB)
  â”‚  â†’ **1 chunk** (>2GB, cannot group)
  â””â”€ large_3gb.parquet (3GB)
     â†’ **1 chunk** (>2GB, cannot group)

Total: 5 chunks
```

### Lite Mode Comparison

| Mode | Files | Total Size | Gen Time | Use Case |
|------|-------|------------|----------|----------|
| **Lite** | 1-35MB | ~120MB | <10s | Local dev, CI, quick tests |
| **Full** | 10MB-3GB | ~7.3GB | ~5min | Pre-release, production validation |

### Lite Mode Benefits

âœ… **Fast iteration** - Test in seconds, not minutes  
âœ… **CI-friendly** - Lightweight for automated testing  
âœ… **Resource-efficient** - Won't freeze your laptop  
âœ… **Same logic** - Tests the same chunking behavior  
âœ… **Optional full mode** - Available when needed  

---

## ğŸ› ï¸ Manual Testing

### Generate Test Data Only

```bash
# Small files (default)
./generate_testdata.sh

# Medium files
./generate_testdata.sh --size medium

# Large files
./generate_testdata.sh --size large

# Specific format only
./generate_testdata.sh --format parquet
./generate_testdata.sh --format csv
./generate_testdata.sh --format json
```

### Generate Chunk Test Files

```bash
# Lite mode (fast, lightweight)
./generate-testdata -chunk-test -lite -format=parquet

# Full mode (production sizes)
./generate-testdata -chunk-test -format=parquet

# All formats (lite mode)
./generate-testdata -chunk-test -lite -format=all

# Generate specific size
./generate-testdata -target-mb=500 -format=parquet
./generate-testdata -target-mb=2500 -format=parquet
```

### Run Specific Tests

```bash
# Start services
docker compose up -d

# Generate data
./generate_testdata.sh --size small

# Upload to MinIO
./upload_to_minio.sh

# Test Parquet only
cd ../../..
./build.sh driver-s3 sync \
  --config drivers/s3/examples/source-parquet.json \
  --catalog drivers/s3/examples/streams-parquet.json \
  --destination drivers/s3/examples/destination.json

# Test CSV only
./build.sh driver-s3 sync \
  --config drivers/s3/examples/source-csv.json \
  --catalog drivers/s3/examples/streams-csv.json \
  --destination drivers/s3/examples/destination.json

# Test JSON only
./build.sh driver-s3 sync \
  --config drivers/s3/examples/source-json.json \
  --catalog drivers/s3/examples/streams-json.json \
  --destination drivers/s3/examples/destination.json
```

---

## ğŸ” Verification & Monitoring

### Verify Data in Iceberg

```bash
# Connect to PostgreSQL
docker exec -it olake-iceberg-catalog psql -U iceberg -d iceberg

# List tables
\dt

# Check record counts
SELECT COUNT(*) FROM parquet_users;
SELECT COUNT(*) FROM parquet_orders;
SELECT COUNT(*) FROM parquet_products;

SELECT COUNT(*) FROM csv_users;
SELECT COUNT(*) FROM csv_orders;

SELECT COUNT(*) FROM json_users;
SELECT COUNT(*) FROM json_orders;

# Check cursor field
SELECT _olake_last_modified, COUNT(*) 
FROM parquet_users 
GROUP BY _olake_last_modified;

# Sample data
SELECT * FROM parquet_users LIMIT 5;
SELECT status, COUNT(*) FROM parquet_orders GROUP BY status;
```

### MinIO Console

```bash
open http://localhost:9001
# Username: admin
# Password: password
```

### View Uploaded Files

```bash
# List all files
docker exec olake-s3-minio mc ls myminio/source-data/ --recursive

# Get file info
docker exec olake-s3-minio mc stat myminio/source-data/parquet/users/data.parquet

# Download file
docker exec olake-s3-minio mc cp myminio/source-data/parquet/users/data.parquet /tmp/
```

### Check Logs

```bash
# MinIO logs
docker logs olake-s3-minio

# PostgreSQL logs
docker logs olake-iceberg-catalog

# Follow logs
docker logs -f olake-s3-minio

# Run sync and capture logs
./build.sh driver-s3 sync \
  --config config-chunk-test.json \
  --catalog streams-chunk-test.json \
  --destination destination.json 2>&1 | tee chunk_test.log

# Look for chunking patterns
grep -i "chunk" chunk_test.log
grep "Processing.*files" chunk_test.log
```

---

## ğŸ› Troubleshooting

### Docker Not Running

```bash
# Check Docker status
docker info

# Start Docker Desktop (macOS)
open -a Docker

# Restart services
docker compose down
docker compose up -d
```

### Test Data Generation Fails

```bash
# Check Go version
go version  # Should be 1.19+

# Rebuild generator
cd testdata
go build -o ../generate-testdata main.go
cd ..

# Test generator
./generate-testdata -size=small -format=parquet
```

### MinIO Upload Fails

```bash
# Check MinIO is running
docker ps | grep minio

# Check buckets exist
docker exec olake-s3-minio mc ls myminio/

# Create bucket if missing
docker exec olake-s3-minio mc mb myminio/source-data --ignore-existing
```

### Iceberg Tables Not Created

```bash
# Check PostgreSQL
docker exec olake-iceberg-catalog pg_isready -U iceberg

# List databases
docker exec olake-iceberg-catalog psql -U iceberg -l

# Check for errors in sync logs
./build.sh driver-s3 sync --config source-parquet.json ... 2>&1 | tee sync.log
```

### Docker Port Conflicts

If you see:
```
Bind for 0.0.0.0:9000 failed: port is already allocated
```

**Solution:** The test script now auto-detects running containers and retries with network prune if needed.

### Out of Disk Space

```bash
# Check usage
df -h

# Cleanup
rm -rf test_data test_data_*
docker compose down -v
docker system prune -a
```

### Memory Issues (Large Tests)

```bash
# Monitor memory
docker stats

# Use medium instead
./run_tests.sh --size medium

# Or custom smaller size
./generate-testdata -target-mb=500
```

---

## ğŸ“š Test Data Generator

### Go Program Location
`testdata/main.go`

### Build Manually
```bash
cd testdata
go build -o ../generate-testdata main.go
```

### Usage
```bash
./generate-testdata -size=small -format=all -output=test_data
./generate-testdata -size=medium -format=parquet -output=custom_dir
```

### Supported Options
- `-size`: small, medium, large
- `-format`: parquet, csv, json, all
- `-output`: output directory path
- `-chunk-test`: Generate chunk boundary test files
- `-lite`: Use lite mode for chunk tests (smaller files)
- `-target-mb`: Generate specific file size in MB

---

## ğŸ¯ Recommended Test Sequence

### For Development

```bash
# 1. Unit tests (fast feedback)
go test ./drivers/s3/internal/... -v

# 2. Quick integration (verify end-to-end)
cd drivers/s3/examples
./run_tests.sh

# 3. Chunk testing (verify boundary logic)
./test_chunking.sh
```

### Before PR/Release

```bash
# 1. All unit tests with coverage
go test ./drivers/s3/internal/... -cover

# 2. Medium integration test
cd drivers/s3/examples
./run_tests.sh --size medium

# 3. Chunk boundary testing
./test_chunking.sh

# 4. Large scale (optional, if major changes)
./run_tests.sh --size large
```

---

## ğŸ“ Project Structure

```
drivers/s3/
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ s3.go                    # Main driver
â”‚   â”œâ”€â”€ sync.go                  # Unified sync logic
â”‚   â”œâ”€â”€ config.go                # Configuration
â”‚   â”œâ”€â”€ s3_test.go               # Integration tests
â”‚   â”œâ”€â”€ sync_test.go             # Sync logic tests
â”‚   â”œâ”€â”€ edge_cases_test.go       # Edge case tests
â”‚   â””â”€â”€ config_test.go           # Config tests
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ testdata/
â”‚   â”‚   â””â”€â”€ main.go              # Go test data generator
â”‚   â”œâ”€â”€ generate_testdata.sh    # Generator wrapper
â”‚   â”œâ”€â”€ run_tests.sh             # Test suite runner
â”‚   â”œâ”€â”€ test_chunking.sh         # Chunk boundary tests
â”‚   â”œâ”€â”€ upload_to_minio.sh      # MinIO upload script
â”‚   â”œâ”€â”€ docker-compose.yml       # Docker services
â”‚   â””â”€â”€ README.md               # This file
â”‚
â””â”€â”€ parser/                      # Separate parser package
    â”œâ”€â”€ parser.go                # Parser interface
    â”œâ”€â”€ csv.go                   # CSV parser
    â”œâ”€â”€ json.go                  # JSON parser
    â””â”€â”€ parquet.go               # Parquet parser
```

---

## ğŸ”§ Technology Stack

- **Go 1.19+** - Test data generation, unit tests
- **Shell (Bash)** - Test orchestration
- **Docker** - MinIO, PostgreSQL/Iceberg
- **MinIO** - S3-compatible storage
- **PostgreSQL** - Iceberg catalog
- **Parquet-go** - Parquet file handling

---

## ğŸ“ˆ Test Execution Times

| Test Type | Records | Data Size | Time | Memory |
|-----------|---------|-----------|------|--------|
| Unit tests | N/A | N/A | ~2s | <100MB |
| Small integration | ~65K | ~50MB | ~2min | ~500MB |
| Medium integration | ~2.6M | ~2GB | ~10min | ~2GB |
| Large integration | ~15.5M | ~10GB | ~45min | ~4GB |
| Chunk boundary (lite) | ~1M | ~120MB | ~1min | ~500MB |
| Chunk boundary (full) | ~50M | ~7GB | ~5min | ~2GB |

---

## âœ… What Gets Tested

### Functional
âœ… Multi-format support (Parquet, CSV, JSON)  
âœ… Compression (gzip, snappy, none)  
âœ… Stream grouping by folder  
âœ… Schema inference  
âœ… Incremental sync with cursor  
âœ… State management  
âœ… Chunk-based parallel processing  
âœ… 2GB chunk boundaries  

### Data Quality
âœ… Record counts match expectations  
âœ… No NULL primary keys  
âœ… Timestamps parsed correctly  
âœ… Data types correct  
âœ… Cursor field present  
âœ… Compression roundtrips  

### Performance
âœ… Small files group efficiently  
âœ… Large files (>2GB) stream properly  
âœ… Memory stays within bounds  
âœ… Parallel processing works  

---

## ğŸ‰ Success Criteria

After running all tests, you should see:

- âœ… **Unit tests:** 154+ passing
- âœ… **Small integration:** ~65K records synced
- âœ… **Chunk testing:** 8 files, ~5 chunks, correct grouping
- âœ… **All formats:** Parquet, CSV, JSON working
- âœ… **All compressions:** Gzip, Snappy, None working
- âœ… **Iceberg tables:** Created with correct schemas
- âœ… **Cursor field:** `_olake_last_modified` present
- âœ… **No errors:** Clean logs, no panics

---

## ğŸ§¹ Cleanup

```bash
# Stop containers
docker compose down

# Remove volumes (deletes all data)
docker compose down -v

# Remove generated test data
rm -rf test_data test_data_*

# Remove generated binary
rm -f generate-testdata
```

---

## ğŸ‰ Summary

### What We've Built

âœ… **Pure Go + Shell testing** (no Python!)  
âœ… **One-command testing** for all scenarios  
âœ… **154+ comprehensive unit tests**  
âœ… **Multiple integration test sizes**  
âœ… **Chunk boundary verification with Lite Mode**  
âœ… **Large dataset support** (15.5M records)  

### Quick Commands Reference

```bash
# Unit tests
go test ./drivers/s3/internal/... -v

# Quick integration
cd drivers/s3/examples && ./run_tests.sh

# Large dataset
./run_tests.sh --size large

# Chunk testing (lite mode - fast!)
./test_chunking.sh

# Chunk testing (full mode - comprehensive)
./test_chunking.sh --full

# Custom size
./generate-testdata -target-mb=1000 -format=parquet

# Cleanup
docker compose down -v && rm -rf test_data*
```

---

**Ready to test?** Just run: `./run_tests.sh` ğŸš€
